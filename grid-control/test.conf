[DEFAULT]
dir = .

[global]
module        = CMSSW         ; Available options: CMSSW, UserMod
backend       = grid          ; Available options: [grid], local
workdir       = %(dir)s/work  ; Default: Name of config file
include       = common.conf   ; This config files provides default values

[jobs]
jobs          = 27            ; Maximum number of jobs (truncated to module maximum)
                              ; Default is taken from module maximum
in flight     = 10            ; Maximum number of jobs concurrently submitted - default [jobs]
memory        = 512           ; Requested memory in MB - default [512]
wall time     = 10:00:00      ; Requested wall time in format hh[:mm[:ss]]
                              ; also used for checking the proxy lifetime
cpu time      = 10:00         ; Requested cpu time in format hh[:mm[:ss]] - default = wall time
queue timeout = 2:00:00       ; Resubmit jobs after staying some time in initial state - default [off]
;node timeout = 0:10:00       ; Cancel job after some time on worker node - default [off]
monitor job   = true          ; Enable dashboard integration to monitor job - default [off]
shuffle       = True          ; Submit jobs in random order - default [off]
seeds         = 32,51,346,234 ; Random seeds used in the job via __SEED_j__
                              ; __SEED_0__ = 32, 33, 34, ... for first, second, third job
                              ; __SEED_1__ = 51, 52, 53, ... for first, second, third job
                              ; Default: Generate 10 random seeds

[events]
; There are many variables set for these scripts according to the
; environment variables the job will have during execution - the are prefixed "GC_"
;on submit    = on_submit.sh  ; This script is called with jobnr, jobid
;on status    = on_status.sh  ; This script is called with jobnr, jobid, status
;on output    = on_output.sh  ; This script is called with jobnr, jobid, retcode

[local]
wms           = PBS           ; Select local wms: PBS, LSF, SGE, SLURM - Default: best guess
queue         = short         ; Select local queue
group         = cmsqcd        ; Select local fairshare group
sandbox path  = %(dir)s/sbox  ; Path to sandboxes - Default: $WORKDIR/sandbox

[grid]
proxy         = VomsProxy     ; Available options: [TrivialProxy], VomsProxy
wms           = GliteWMS      ; Available options: [GliteWMS], Glite, LCG
sites         = -blah         ; Whitelist / Blacklist sites (prefix "-")

[lcg]
;config-vo    = %(dir)s/glite_wl_ui.conf	; LCG backend specific configuration (WMS, ...)

[glite]
;config-vo    = %(dir)s/glite_wl_ui.conf	; Glite backend specific configuration (WMS, ...)

[glite-wms]
;config       = %(dir)s/glite_wms.conf		; GliteWMS backend specific configuration (WMS, ...)

[storage]
; se path specifies the location used to transfer "se input files" at the beginning of the job
; and "se output files" at the end of the job
; Currently supported protocols: gsiftp srm file dir
se path       = gsiftp://ekp-lcg-se.physik.uni-karlsruhe.de//wlcg/data/users/cms/my_username
;se path      = srm://dcache-se-cms.desy.de:8443/pnfs/desy.de/cms/tier2/store/user/
;se path      = dir:///path/to/directory

se min size	      = -1                      ; Job fails if any output file is smaller than se min size
se output files   = out.root                ; Specifies the files to be transfered after the job has finished
se output pattern = job___MY_JOBID_____X__  ; This pattern is applied to the se output file
                                            ; to get the destination filename
											; Default: job___MY_JOBID_____NICK_____X__
                                            ; __X__         : Marks the spot of the original filename
                                            ; __MY_JOBID__  : Continous job number 0..max
                                            ; __DATE__      : Current date eg. 2009-06-24
                                            ; __TIMESTAMP__ : Current timestamp eg. 1245855548
                                            ; __RANDOM__    : Random number between 0 and 900000000
											; __NICK__      : Nickname of dataset for CMSSW jobs
                                            ; This is just the list of the most important substituions available

se input files   = file                         ; Specifies the files to be transfered before the job starts
se input pattern = __X__                    ; This pattern is applied to the se input file
                                            ; to get the source filename. Same rules as output pattern
											; Default: __X__

; used = max used space by own job files
; During the duration of the job both the available and used space is monitored
; The following entries specify thresholds (in mb) which cause the job to abort
; Landing zone is the directory the job initially starts in
landing zone space used = 100               ; Maximum amount of space used by the job
                                            ; Default: 100 mb
landing zone space left = 50                ; Minimum amout of disk space available
                                            ; Default: 1 mb
; One of the first orders of business for each job is to find a large
; scratch space which will be used as working directory of the job
; If the landing zone ITSELF is the scratch space, the scratch thresholds apply
scratch space used = 5000                   ; Maximum amount of space used by the job
                                            ; Default: 5000 mb
scratch space left = 1000                   ; Minimum amout of disk space available
                                            ; Default: 1 mb

[UserMod]
executable   = default.sh                   ; Name of the script / application
arguments    = param1 param2 param3         ; Parameters for the user application
input files  = input.txt config.sh          ; Input files send together with the job
                                            ; Only for small files - send large files via SE!
output files = output.tgz                   ; Output files retrived together with the job
                                            ; Only for small files - send large files via SE!

[CMSSW]
project area     = %(dir)s/CMSSW_3_1_0 ; Path to an existing CMSSW project area used for running the jobs
;scram project   = CMSSW CMSSW_3_1_0   ; Used to create a vanilla CMSSW project, eg. for production
;scram arch       = slc4_ia32_gcc345   ; Select scram architecture
                                       ; When given a project area, the default arch is taken from the project
                                       ; Has to be specified when using scram project

; Path to CMSSW config file 
config file      = %(project area)s/src/Test/Analysis/cmssw-grid.py

use requirements = True                ; Write CMSSW version into job requirements, Default: True
gzip output      = True                ; Gzip the output of the cmsRun command, Default: True
se runtime       = True                ; Send CMSSW runtime via SE instead of sending it together with the job, Default: False
se runtime force = True                ; Force to overwrite existing se runtimes, Default: True

; Comment out the variable [jobs] jobs in order to run over all events of the dataset
; Specifiy one dataset 
;dataset = /WmunuJets_pt_80_120/CMSSW_1_3_1-Spring07-1243/GEN-SIM-DIGI-RECO
; Or several by starting with an empty line
dataset =
	/WmunuJets_pt_80_120/CMSSW_1_3_1-Spring07-1243/GEN-SIM-DIGI-RECO#2c1efdb8-d9ba-46d4-b067-72c3d8b19abf
	QCD : /QCD_Pt_470_600/CMSSW_1_5_2-CSA07-2096/GEN-SIM-DIGI-RECO@cms_dbs_prod_local_09
	/CSA07JetMET/CMSSW_1_6_7-CSA07-Tier0-A1-Gumbo/RECO
	Zmm : DBS:/Zmumu/Summer08_IDEAL_V9_v1/GEN-SIM-RAW
;	Nick1 : list:/path/to/local/dbsfile
;	Nick2 : file:/pnfs/to/file
; dataset syntax:
;     [ [<nickname> :] <protocol> :] <dataset specifier>
;     Syntax for the dataset specifier depends on the protocol:
;          DBS : <dataset path>[@<instance>][#<block>]
;         list : <path to list of data files>
;         file : <path to data file>

; Select default dataset protocol
; Available: [DBSApiv2] FileProvider ListProvider
dbsapi           = DBSApiv2

; Select default dbs instance for DBSApiv2 datasets
; Default: http://cmsdbsprod.cern.ch/cms_dbs_prod_global/servlet/DBSServlet (Global CMSSW production DBS server instance)
dbs instance     = http://cmsdbsprod.cern.ch/cms_dbs_prod_global/servlet/DBSServlet

dataset splitter = DefaultSplitter     ; Available options: [DefaultSplitter] FileBoundarySplitter
                                       ; DefaultSplitter: splits on block boundaries and slices each block into
                                       ;                  jobs with "events per job" events per job
                                       ; FileBoundarySplitter: splits on file and block boundaries
                                       ;                  and interpret "events per job" as files per job
events per job   = 5000                ; Set granularity of dataset splitter

; Select files to be included in the CMSSW runtime
; Default: -.* -config lib module */data *.xml *.sql *.cf[if] *.py
area files       = -.* -config lib module */data *.xml *.sql *.cf[if] *.py

;input files     =                     ; Input files send together with the job
                                       ; Only for small files - send large files via SE!
;output files    =                     ; Output files retrived together with the job
                                       ; Only for small files - send large files via SE!
