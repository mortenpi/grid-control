; ==============================================================================
; General options
; ==============================================================================

[DEFAULT]
dir = .

[global]
module        = CMSSW         ; Available options: 
                              ; CMSSW, UserMod, SimpleParaMod, FileParaMod, LinkedParaMod
                              ; |ADVANCED USAGE: Classes can be specified in different ways:
                              ; | * grid_control.user_mod.UserMod (fully qualified path)
                              ; | * user_mod.UserMod (lookup in grid_control is default)
                              ; | * UserMod (short form in case of import by __init__.py)
backend       = grid          ; Available options: [grid], local
workdir       = %(dir)s/work  ; Default: Name of config file
include       = common.conf   ; This config files provides default values
cmdargs       = -G -c         ; Automatically added command line arguments - default: empty
                              ; Here, -G -c enables the GUI and continuous mode

[jobs]
jobs          = 27            ; Maximum number of jobs (truncated to module maximum)
                              ; Default is taken from module maximum
in flight     = 10            ; Maximum number of concurrently submitted jobs - default: no limit
in queue      = -1            ; Maximum number of queued jobs - default: No limit
max retry     = 4             ; Number of resubmission attempts for failed jobs - default: no limit

memory        = 512           ; Requested memory in MB - default [512]
                              ; NAF jobs need 2000 MB !
wall time     = 10:00:00      ; Requested wall time in format hh[:mm[:ss]]
                              ; also used for checking the proxy lifetime
cpu time      = 10:00         ; Requested cpu time in format hh[:mm[:ss]] - default = wall time

queue timeout = 2:00:00       ; Resubmit jobs after staying some time in initial state - default [off]
;node timeout = 0:10:00       ; Cancel job after some time on worker node - default [off]
monitor       = dashboard     ; Monitoring of jobs 
                              ;    dashboard - use dashboard
                              ;    scripts   - call scripts (see [events] section) [default]
shuffle       = True          ; Submit jobs in random order - default [off]
seeds         = 32,51,346,234 ; Random seeds used in the job via @SEED_j@
                              ; @SEED_0@ = 32, 33, 34, ... for first, second, third job
                              ; @SEED_1@ = 51, 52, 53, ... for first, second, third job
                              ; Default: Generate 10 random seeds

[events]
; There are many variables set for these scripts according to the
; environment variables the job will have during execution - they are prefixed "GC_"
; note: the events are only evaluated with "monitor = scripts" in [jobs] section
;on submit    = on_submit.sh  ; This script is called with jobnr, jobid
;on status    = on_status.sh  ; This script is called with jobnr, jobid, status
;on output    = on_output.sh  ; This script is called with jobnr, jobid, retcode
;on finish    = on_finish.sh  ; This script is called after all jobs are finished with #Jobs

[dashboard]
application   = Herwigpp      ; Defines application name - default [shellscript]
task          = production    ; Task type reported to the dashboard - default [analysis]

; ==============================================================================
; Backend options
; ==============================================================================

[local]
wms           = PBS           ; Select local wms: PBS, LSF, SGE, SLURM, Host - Default: best guess
broker        = DummyBroker   ; Available options: [DummyBroker], SimpleBroker
queue         = short         ; Select local queue
group         = cmsqcd        ; Select local fairshare group
sandbox path  = %(dir)s/sbox  ; Path to sandboxes - Default: $WORKDIR/sandbox
scratch path  = /tmp          ; Override scratch directory on nodes - Default: determined by job

[grid]
proxy         = VomsProxy     ; Available options: [TrivialProxy], VomsProxy
wms           = GliteWMS      ; Available options: [GliteWMS], Glite, LCG
sites         = -blah         ; Whitelist / Blacklist sites (prefix "-")

[proxy]
ignore warnings   = True      ; Ignore problems with the proxy as long as all
                              ; necessary information is provided (Default: False)

[glite-wms]
;config = docs/glite_wms_ALL.conf       ; GliteWMS backend specific configuration (WMS, ...)

; ==============================================================================
; Storage options
; ==============================================================================

[storage]
; se path specifies the location used to transfer "se input files" at the beginning of the job
; and "se output files" at the end of the job
; Currently supported protocols: gsiftp srm dir
se path       = gsiftp://ekp-lcg-se.physik.uni-karlsruhe.de//wlcg/data/users/cms/my_username
;se path      = srm://dcache-se-cms.desy.de:8443/pnfs/desy.de/cms/tier2/store/user/
;se path      = srm://dcache-se-cms.desy.de:8443//srm/managerv2?SFN=/pnfs/desy.de/cms/tier2/store/user/
;se path      = rfio:///castor/cern.ch/user/x/username
;se path      = dir:///absolute/path/to/directory

se min size       = -1                  ; Job fails if any output file is smaller than se min size
se output files   = out.root            ; Specifies the files to be transfered after the job has finished
se output pattern = job_@MY_JOBID@_@X@  ; This pattern is applied to the se output file
                                        ; to get the destination filename
                                        ; Default: @NICK@job_@MY_JOBID@_@X@
                                        ; @X@         : Marks the spot of the original filename
                                        ; @MY_JOBID@  : Continous job number 0..max
                                        ; @NICK@      : Nickname of dataset for CMSSW jobs
                                        ; @CONF@      : Name of config file (without extension .conf)
                                        ; @DATE@      : Current date eg. 2009-06-24
                                        ; @TIMESTAMP@ : Current timestamp eg. 1245855548
                                        ; @RANDOM@    : Random number between 0 and 900000000
                                        ; This is just the list of the most important substituions available
                                        ; A complete list is available via the --help-vars option
                                        ; The variables can also be surounded by "__" instead of "@"

se input files    = file                ; Specifies the files to be transfered before the job starts
se input pattern  = @X@                 ; This pattern is applied to the se input file
                                        ; to get the source filename. Same rules as output pattern
                                        ; Default: @X@

; During the duration of the job both the available and used space is monitored
; The following entries specify thresholds (in mb) which cause the job to abort
; Landing zone is the directory the job initially starts in
landing zone space used = 100           ; Maximum amount of space used by the job
                                        ; Default: 100 mb
landing zone space left = 50            ; Minimum amout of disk space available
                                        ; Default: 1 mb
; One of the first orders of business for each job is to find a large
; scratch space which will be used as working directory of the job
; If the landing zone ITSELF is the scratch space, the scratch thresholds apply
scratch space used = 5000               ; Maximum amount of space used by the job
                                        ; Default: 5000 mb
scratch space left = 1000               ; Minimum amout of disk space available
                                        ; Default: 1 mb

; ==============================================================================
; User Module
; ==============================================================================

[UserMod]
executable   = default.sh               ; Name of the script / application
arguments    = param1 param2 param3     ; Parameters for the user application
                                        ; Known variables in the form @VAR@ will be replaced.
                                        ; A complete list is available via the --help-vars option
input files  = input.txt config.sh      ; Input files send together with the job
                                        ; Only for small files - send large files via SE!
subst files  = config.sh                ; These input files will be subjected to variable substituion
                                        ; A complete list is available via the --help-vars option
output files = output.gz                ; Output files retrived together with the job
                                        ; Only for small files - send large files via SE!
depends      = CMSSW                    ; Depends on certain environments eg. Herwig++ job which needs
                                        ; CMSSW. Possible values: CMSSW, gLite
                                        ; The corresponding files are share/env.cmssw.sh, share/env.glite.sh

; ==============================================================================
; CMSSW Module
; ==============================================================================

[CMSSW]
project area     = %(dir)s/CMSSW_3_1_0  ; Path to an existing CMSSW project area used for running the jobs
;scram project   = CMSSW CMSSW_3_1_0    ; Used to create a vanilla CMSSW project, eg. for production
;scram arch       = slc4_ia32_gcc345    ; Select scram architecture
                                        ; When given a project area, the default arch is taken from the project
                                        ; Has to be specified when using scram project
cmssw dir        = /path/for/VO_CMS_SW_DIR ; Path to manually add cmssw dir to search path

; Path to CMSSW config file 
config file      = %(project area)s/src/Test/Analysis/cmssw-grid.py

use requirements = True                 ; Write CMSSW version into job requirements, Default: True
gzip output      = True                 ; Gzip the output of the cmsRun command, Default: True
se runtime       = True                 ; Send CMSSW runtime via SE instead of sending it together with the job, Default: False
se runtime force = True                 ; Force to overwrite existing se runtimes, Default: True

; Comment out the variable [jobs] jobs in order to run over all events of the dataset
; Specifiy one dataset 
;dataset = /WmunuJets_pt_80_120/CMSSW_1_3_1-Spring07-1243/GEN-SIM-DIGI-RECO
; Or several by starting with an empty line
dataset =
	/WmunuJets_pt_80_120/CMSSW_1_3_1-Spring07-1243/GEN-SIM-DIGI-RECO#2c1efdb8-d9ba-46d4-b067-72c3d8b19abf
	QCD : /QCD_Pt_470_600/CMSSW_1_5_2-CSA07-2096/GEN-SIM-DIGI-RECO@cms_dbs_prod_local_09
	/CSA07JetMET/CMSSW_1_6_7-CSA07-Tier0-A1-Gumbo/RECO
	Zmm : DBS:/Zmumu/Summer08_IDEAL_V9_v1/GEN-SIM-RAW
;	Nick1 : list:/path/to/local/dbsfile
;	Nick2 : file:/pnfs/to/file|1200
; dataset syntax:
;     [<nickname> : [<protocol> :]] <dataset specifier>
;     Syntax for the dataset specifier depends on the protocol:
;          dbs : <dataset path>[@<instance>][#<block>]
;         list : <path to list of data files>[@<forced prefix>][%<selected dataset>[#<selected block>]]
;                The list provider allows to select single datasets / blocks from a file
;         file : <path to data file>|<number of events>[@SE1,SE2]

; Select default dataset protocol
; Available: [DBSApiv2] (=dbs) FileProvider (=file) ListProvider (=list)
dataset provider = DBSApiv2

; Select default dbs instance for DBSApiv2 datasets
; Default: http://cmsdbsprod.cern.ch/cms_dbs_prod_global/servlet/DBSServlet (Global CMSSW production DBS server instance)
dbs instance     = http://cmsdbsprod.cern.ch/cms_dbs_prod_global/servlet/DBSServlet
dbs blacklist T1 = True ; Blacklist data on T1s

dataset splitter = EventBoundarySplitter ; Available options:
                                         ; EventBoundarySplitter: splits on block boundaries and slices each block into
                                         ;                        jobs with "events per job" events per job
                                         ;                        (Default for CMSSW jobs)
                                         ; HybridSplitter:        hybrid of EventBoundarySplitter and FileBoundarySplitter,
                                         ;                        splits on file and block boundaries and tries to use
                                         ;                        approximately "events per job" events per job
                                         ; FileBoundarySplitter:  splits on file and block boundaries
                                         ;                        and interpret "files per job" as files per job
                                         ;                        (Default for UserMod jobs)
                                         ; BlockBoundarySplitter: split along block boundaries

events per job   = 5000                  ; Set granularity of dataset splitter
files per job    = 5                     ; Set granularity of dataset splitter

lumi filter      = 132440:1-132440:401,  ; apply global luminosity block filter for all DBS datasets
                   132442-132447,        ; Syntax: <RUN>[:<LUMI>]-[<RUN>[:<LUMI>]], ...
                   132473, 132652,       ; (open ended ranges possible)
                   /path/to/json_file    ; alternative way to specify lumi sections is via json file

; Select files to be included in the CMSSW runtime
; Default: -.* -config lib module */data *.xml *.sql *.cf[if] *.py
area files       = -.* -config lib module */data *.xml *.sql *.cf[if] *.py

;input files     =                      ; Input files send together with the job
                                        ; Only for small files - send large files via SE!
;subst files     =                      ; These input files will be subjected to variable substituion
                                        ; A complete list is available via the --help-vars option
                                        ; Default: the CMSSW config file
;output files    =                      ; Output files retrived together with the job
                                        ; Only for small files - send large files via SE!

; ==============================================================================
; Parameter Module
;   The parameter module allows to run jobs from another module with
;   different parameters.
; ==============================================================================

[ParaMod]
module           = CMSSW                ; Available options: CMSSW, UserMod
jobs             = 4                    ; In case the selected module doesn't specify the maximum number
                                        ; of jobs, set the basic number of jobs (to be multiplied by
                                        ; parameter space size). Default: 1

; ------------------------
; SimpleParaMod
;   The following is specific to SimpleParaMod:
;   SimpleParaMod provides the job with a single parameter
; ------------------------

parameter name   = MYTESTPARAM          ; Specify name of parameter; Default: PARAMETER
                                        ; Parameter is set as an environment variable
                                        ; and is useable in subst files via eg. @MYTESTPARAM@
parameter values = 23 42 123            ; Specify parameter values
                                        ; In conjunction with jobs = 4 above this results in
                                        ; 4 x 3 = 12 jobs to be submitted in case the module
                                        ; itself does not specify the maximum number of jobs.
                                        ; If the module does specify the max #jobs
                                        ; (CMSSW with dataset - eg. 6) this would give 6 x 3 = 18 jobs

; ------------------------
; LinkedParaMod
;   The following is specific to LinkedParaMod:
;   LinkedParaMod provides the job with several parameters at once
; ------------------------

parameter name   = CUTLOW:CUTHIGH:XSEC  ; Specify names of parameters; Default: PARAMETER
                                        ; The parameters are set as environment variables
                                        ; and are useable in subst files via eg. @XSEC@
parameter values =                      ; Specify parameter values
    20 :  40 : 1.342                    ; In conjunction with jobs = 4 above this results in
    40 : 100 : 2.124                    ; 4 x 5 = 20 jobs to be submitted in case the module
   200 : 300 : 3.134                    ; itself does not specify the maximum number of jobs.
   300 : 600 : 1.235                    ; If the module does specify the max #jobs
   700 : 800 : 0.942                    ; (CMSSW with dataset - eg. 6) this would give 6 x 5 = 30 jobs
                                        ; The first job would get CUTLOW=20, CUTHIGH=40, XSEC=1.342
                                        ; The last job would get CUTLOW=700, CUTHIGH=800, XSEC=0.942

; ------------------------
; FileParaMod
;   The following is specific to FileParaMod:
;   FileParaMod provides the job with several parameters at once from a csv file
; ------------------------

parameter source = parameters.csv       ; Specify the file the parameters are taken from.
                                        ; The header specifies the variable names
parameter source dialect = excel-tab    ; Default is to guess the csv format from the file itself
                                        ; Available options: [sniffed], excel, excel-tab

; ------------------------
; UberParaMod
;   builds all possible combinations of parameters and parameter tuples.
;   This module is similar to the LinkedParaMod and ParaMod itself.
; ------------------------

parameters  = spam (ham, eggs)    ; Specify a parameter and two linked
                                  ; parameters
spam        = 0 1                 ; Assign values to the single parameter
(ham, eggs) = (A, a) (B, b)       ; Assign values to the linked parameters

; This gives [spam, ham, eggs]: [0,A,a], [0,B,b], [1,A,a] and [1,B,b] as
; parameter combinations

; In more complex situations which are outside the scope of either
; SimpleParaMod, FileParaMod or LinkedParaMod: => derive own module from ParaMod (very easy)
